2021-06-16 15:42:55,839 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-master/10.128.0.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-kms-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn:/home/hadoop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-06-16 15:42:55,850 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-16 15:42:55,971 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-16 15:42:56,216 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-16 15:42:56,378 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-16 15:42:56,378 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-16 15:42:56,404 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://node-master:9000
2021-06-16 15:42:56,404 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use node-master:9000 to access this namenode/service.
2021-06-16 15:42:56,601 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-06-16 15:42:56,630 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2021-06-16 15:42:56,644 INFO org.eclipse.jetty.util.log: Logging initialized @1302ms
2021-06-16 15:42:56,751 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-16 15:42:56,764 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-16 15:42:56,769 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-16 15:42:56,771 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-16 15:42:56,772 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-16 15:42:56,772 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-16 15:42:56,797 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-16 15:42:56,797 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-16 15:42:56,810 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2021-06-16 15:42:56,811 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2021-06-16 15:42:56,846 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,AVAILABLE}
2021-06-16 15:42:56,847 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-06-16 15:42:56,916 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@13bc8645{/,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2021-06-16 15:42:56,923 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 15:42:56,923 INFO org.eclipse.jetty.server.Server: Started @1582ms
2021-06-16 15:42:57,236 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:42:57,237 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:42:57,237 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 15:42:57,237 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 15:42:57,244 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:42:57,244 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:42:57,285 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2021-06-16 15:42:57,298 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2021-06-16 15:42:57,300 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2021-06-16 15:42:57,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2021-06-16 15:42:57,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)
2021-06-16 15:42:57,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-16 15:42:57,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-16 15:42:57,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-16 15:42:57,339 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-06-16 15:42:57,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2021-06-16 15:42:57,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-16 15:42:57,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-16 15:42:57,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 16 15:42:57
2021-06-16 15:42:57,356 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-16 15:42:57,356 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 15:42:57,358 INFO org.apache.hadoop.util.GSet: 2.0% max memory 843 MB = 16.9 MB
2021-06-16 15:42:57,358 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-16 15:42:57,367 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2021-06-16 15:42:57,376 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-16 15:42:57,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-16 15:42:57,408 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2021-06-16 15:42:57,428 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-16 15:42:57,428 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 15:42:57,428 INFO org.apache.hadoop.util.GSet: 1.0% max memory 843 MB = 8.4 MB
2021-06-16 15:42:57,428 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-16 15:42:57,430 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-16 15:42:57,430 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2021-06-16 15:42:57,430 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-16 15:42:57,430 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2021-06-16 15:42:57,436 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2021-06-16 15:42:57,439 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2021-06-16 15:42:57,445 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-16 15:42:57,445 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 15:42:57,445 INFO org.apache.hadoop.util.GSet: 0.25% max memory 843 MB = 2.1 MB
2021-06-16 15:42:57,445 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-16 15:42:57,455 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-16 15:42:57,455 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-16 15:42:57,455 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-16 15:42:57,460 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-16 15:42:57,460 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-16 15:42:57,463 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-16 15:42:57,463 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 15:42:57,463 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 843 MB = 259.0 KB
2021-06-16 15:42:57,463 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-16 15:42:57,478 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hadoop/data/nameNode/in_use.lock acquired by nodename 3226@node-master
2021-06-16 15:42:57,521 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hadoop/data/nameNode/current
2021-06-16 15:42:57,521 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2021-06-16 15:42:57,521 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2021-06-16 15:42:57,643 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-06-16 15:42:57,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-16 15:42:57,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/hadoop/data/nameNode/current/fsimage_0000000000000000000
2021-06-16 15:42:57,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-16 15:42:57,694 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2021-06-16 15:42:57,898 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-16 15:42:57,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 432 msecs
2021-06-16 15:42:58,121 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-master:9000
2021-06-16 15:42:58,143 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2021-06-16 15:42:58,164 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-16 15:42:58,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2021-06-16 15:42:58,495 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:42:58,528 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-16 15:42:58,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2021-06-16 15:42:58,599 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2021-06-16 15:42:58,599 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-06-16 15:42:58,599 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-16 15:42:58,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-06-16 15:42:58,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-16 15:42:58,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-16 15:42:58,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-16 15:42:58,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-16 15:42:58,680 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 56 msec
2021-06-16 15:42:58,697 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-16 15:42:58,699 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-16 15:42:58,705 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-master/10.128.0.9:9000
2021-06-16 15:42:58,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-16 15:42:58,709 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2021-06-16 15:42:58,744 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 34 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2021-06-16 15:42:58,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-16 15:43:02,485 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 15:43:02,487 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.9:9866
2021-06-16 15:43:02,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 108100fe-7661-4e2c-8041-5d1d21d2cc03 (10.128.0.9:9866).
2021-06-16 15:43:02,695 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 for DN 10.128.0.9:9866
2021-06-16 15:43:02,788 INFO BlockStateChange: BLOCK* processReport 0x205cd3181b88dddd: Processing first storage report for DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 from datanode 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 15:43:02,790 INFO BlockStateChange: BLOCK* processReport 0x205cd3181b88dddd: from storage DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 node DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 15:44:06,022 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.128.0.9
2021-06-16 15:44:06,022 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-16 15:44:06,022 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 1
2021-06-16 15:44:06,022 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2021-06-16 15:44:06,024 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 11 
2021-06-16 15:44:06,025 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000001 -> /home/hadoop/data/nameNode/current/edits_0000000000000000001-0000000000000000002
2021-06-16 15:44:06,044 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2021-06-16 15:44:06,201 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/fsimage_0000000000000000000, fileSize: 393. Sent total: 393 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 15:44:06,238 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000001-0000000000000000002, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 15:44:06,547 INFO org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /home/hadoop/data/nameNode/current/fsimage.ckpt_0000000000000000002 took 0.00s.
2021-06-16 15:44:06,547 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 393 bytes.
2021-06-16 15:44:06,551 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2021-06-16 15:47:06,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 15:47:06,387 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.11:9866
2021-06-16 15:47:06,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d1ed285d-20a6-4d30-888b-6dc1293d773f (10.128.0.11:9866).
2021-06-16 15:47:06,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 15:47:06,406 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.10:9866
2021-06-16 15:47:06,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 2e312f92-a5b9-43a0-9f20-c2777806fca7 (10.128.0.10:9866).
2021-06-16 15:47:06,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6755ed7e-46ab-49db-a914-70207b487e68 for DN 10.128.0.11:9866
2021-06-16 15:47:06,453 INFO BlockStateChange: BLOCK* processReport 0x6b43f2daa16f15ba: Processing first storage report for DS-6755ed7e-46ab-49db-a914-70207b487e68 from datanode d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 15:47:06,453 INFO BlockStateChange: BLOCK* processReport 0x6b43f2daa16f15ba: from storage DS-6755ed7e-46ab-49db-a914-70207b487e68 node DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2021-06-16 15:47:06,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-e513b6ec-517f-4438-bd91-31af0d185455 for DN 10.128.0.10:9866
2021-06-16 15:47:06,484 INFO BlockStateChange: BLOCK* processReport 0x917f57619b287121: Processing first storage report for DS-e513b6ec-517f-4438-bd91-31af0d185455 from datanode 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 15:47:06,484 INFO BlockStateChange: BLOCK* processReport 0x917f57619b287121: from storage DS-e513b6ec-517f-4438-bd91-31af0d185455 node DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2021-06-16 15:47:35,483 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-16 15:47:35,485 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-master/10.128.0.9
************************************************************/
2021-06-16 15:48:17,037 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-master/10.128.0.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-kms-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn:/home/hadoop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-06-16 15:48:17,052 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-16 15:48:17,195 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-16 15:48:17,444 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-16 15:48:17,583 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-16 15:48:17,583 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-16 15:48:17,610 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://node-master:9000
2021-06-16 15:48:17,610 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use node-master:9000 to access this namenode/service.
2021-06-16 15:48:17,798 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-06-16 15:48:17,828 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2021-06-16 15:48:17,841 INFO org.eclipse.jetty.util.log: Logging initialized @1310ms
2021-06-16 15:48:17,943 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-16 15:48:17,957 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-16 15:48:17,962 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-16 15:48:17,964 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-16 15:48:17,964 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-16 15:48:17,965 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-16 15:48:17,987 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-16 15:48:17,987 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-16 15:48:17,997 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2021-06-16 15:48:17,998 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2021-06-16 15:48:18,036 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,AVAILABLE}
2021-06-16 15:48:18,038 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-06-16 15:48:18,120 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@13bc8645{/,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2021-06-16 15:48:18,129 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 15:48:18,129 INFO org.eclipse.jetty.server.Server: Started @1597ms
2021-06-16 15:48:18,461 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:48:18,461 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:48:18,461 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 15:48:18,462 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 15:48:18,469 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:48:18,469 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:48:18,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2021-06-16 15:48:18,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2021-06-16 15:48:18,524 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2021-06-16 15:48:18,525 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2021-06-16 15:48:18,531 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)
2021-06-16 15:48:18,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-16 15:48:18,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-16 15:48:18,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-16 15:48:18,577 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-06-16 15:48:18,589 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2021-06-16 15:48:18,589 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-16 15:48:18,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-16 15:48:18,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 16 15:48:18
2021-06-16 15:48:18,596 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-16 15:48:18,596 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 15:48:18,598 INFO org.apache.hadoop.util.GSet: 2.0% max memory 843 MB = 16.9 MB
2021-06-16 15:48:18,598 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-16 15:48:18,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2021-06-16 15:48:18,618 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-16 15:48:18,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-16 15:48:18,650 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2021-06-16 15:48:18,670 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-16 15:48:18,670 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 15:48:18,670 INFO org.apache.hadoop.util.GSet: 1.0% max memory 843 MB = 8.4 MB
2021-06-16 15:48:18,671 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-16 15:48:18,672 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-16 15:48:18,672 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2021-06-16 15:48:18,673 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-16 15:48:18,673 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2021-06-16 15:48:18,684 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2021-06-16 15:48:18,687 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2021-06-16 15:48:18,706 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-16 15:48:18,706 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 15:48:18,706 INFO org.apache.hadoop.util.GSet: 0.25% max memory 843 MB = 2.1 MB
2021-06-16 15:48:18,706 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-16 15:48:18,722 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-16 15:48:18,722 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-16 15:48:18,722 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-16 15:48:18,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-16 15:48:18,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-16 15:48:18,732 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-16 15:48:18,732 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 15:48:18,732 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 843 MB = 259.0 KB
2021-06-16 15:48:18,732 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-16 15:48:18,745 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hadoop/data/nameNode/in_use.lock acquired by nodename 4829@node-master
2021-06-16 15:48:18,780 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hadoop/data/nameNode/current
2021-06-16 15:48:18,831 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000003 -> /home/hadoop/data/nameNode/current/edits_0000000000000000003-0000000000000000003
2021-06-16 15:48:18,880 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2021-06-16 15:48:18,966 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-06-16 15:48:19,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-16 15:48:19,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2 from /home/hadoop/data/nameNode/current/fsimage_0000000000000000002
2021-06-16 15:48:19,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@35d08e6c expecting start txid #3
2021-06-16 15:48:19,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000003-0000000000000000003 maxTxnsToRead = 9223372036854775807
2021-06-16 15:48:19,005 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000003-0000000000000000003' to transaction ID 3
2021-06-16 15:48:19,021 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000003-0000000000000000003 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-16 15:48:19,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-16 15:48:19,023 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4
2021-06-16 15:48:19,212 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-16 15:48:19,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 477 msecs
2021-06-16 15:48:19,522 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-master:9000
2021-06-16 15:48:19,539 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2021-06-16 15:48:19,554 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-16 15:48:19,831 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2021-06-16 15:48:19,832 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 15:48:19,877 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-16 15:48:19,919 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2021-06-16 15:48:19,923 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2021-06-16 15:48:19,923 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-06-16 15:48:19,923 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-16 15:48:20,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-06-16 15:48:20,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-16 15:48:20,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-16 15:48:20,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-16 15:48:20,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-16 15:48:20,035 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 98 msec
2021-06-16 15:48:20,040 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-16 15:48:20,045 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-16 15:48:20,047 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-master/10.128.0.9:9000
2021-06-16 15:48:20,051 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-16 15:48:20,051 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2021-06-16 15:48:20,058 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 7 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2021-06-16 15:48:20,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-16 15:48:22,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 15:48:22,235 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.11:9866
2021-06-16 15:48:22,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d1ed285d-20a6-4d30-888b-6dc1293d773f (10.128.0.11:9866).
2021-06-16 15:48:22,249 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 15:48:22,249 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.10:9866
2021-06-16 15:48:22,249 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 2e312f92-a5b9-43a0-9f20-c2777806fca7 (10.128.0.10:9866).
2021-06-16 15:48:22,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6755ed7e-46ab-49db-a914-70207b487e68 for DN 10.128.0.11:9866
2021-06-16 15:48:22,808 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-e513b6ec-517f-4438-bd91-31af0d185455 for DN 10.128.0.10:9866
2021-06-16 15:48:22,900 INFO BlockStateChange: BLOCK* processReport 0x88c20a2a10d78353: Processing first storage report for DS-6755ed7e-46ab-49db-a914-70207b487e68 from datanode d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 15:48:22,902 INFO BlockStateChange: BLOCK* processReport 0x88c20a2a10d78353: from storage DS-6755ed7e-46ab-49db-a914-70207b487e68 node DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2021-06-16 15:48:22,903 INFO BlockStateChange: BLOCK* processReport 0x5a6028f2cae2487e: Processing first storage report for DS-e513b6ec-517f-4438-bd91-31af0d185455 from datanode 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 15:48:22,903 INFO BlockStateChange: BLOCK* processReport 0x5a6028f2cae2487e: from storage DS-e513b6ec-517f-4438-bd91-31af0d185455 node DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2021-06-16 15:48:23,606 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 15:48:23,606 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.9:9866
2021-06-16 15:48:23,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 108100fe-7661-4e2c-8041-5d1d21d2cc03 (10.128.0.9:9866).
2021-06-16 15:48:23,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 for DN 10.128.0.9:9866
2021-06-16 15:48:23,705 INFO BlockStateChange: BLOCK* processReport 0x97b2b0662935470c: Processing first storage report for DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 from datanode 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 15:48:23,705 INFO BlockStateChange: BLOCK* processReport 0x97b2b0662935470c: from storage DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 node DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 15:49:26,066 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.128.0.9
2021-06-16 15:49:26,066 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-16 15:49:26,066 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4, 4
2021-06-16 15:49:26,066 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 3 Number of syncs: 2 SyncTimes(ms): 7 
2021-06-16 15:49:26,067 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 3 Number of syncs: 3 SyncTimes(ms): 8 
2021-06-16 15:49:26,068 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000004 -> /home/hadoop/data/nameNode/current/edits_0000000000000000004-0000000000000000005
2021-06-16 15:49:26,068 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 6
2021-06-16 15:49:26,283 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/fsimage_0000000000000000002, fileSize: 393. Sent total: 393 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 15:49:26,312 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000003-0000000000000000003, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 15:49:26,322 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000004-0000000000000000005, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 15:49:26,590 INFO org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /home/hadoop/data/nameNode/current/fsimage.ckpt_0000000000000000005 took 0.00s.
2021-06-16 15:49:26,590 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000005 size 393 bytes.
2021-06-16 15:49:26,594 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2021-06-16 15:49:26,594 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2021-06-16 16:00:25,324 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-06-16 16:02:56,887 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 1 Number of syncs: 4 SyncTimes(ms): 8 
2021-06-16 16:02:56,930 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=10.128.0.9:9866 for /user/hadoop/books/alice.txt._COPYING_
2021-06-16 16:02:57,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/books/alice.txt._COPYING_
2021-06-16 16:02:57,652 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop/books/alice.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1804992934_1
2021-06-16 16:02:57,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=10.128.0.9:9866 for /user/hadoop/books/holmes.txt._COPYING_
2021-06-16 16:02:57,696 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741826_1002 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/books/holmes.txt._COPYING_
2021-06-16 16:02:58,104 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop/books/holmes.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1804992934_1
2021-06-16 16:02:58,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=10.128.0.9:9866 for /user/hadoop/books/frankenstein.txt._COPYING_
2021-06-16 16:02:58,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741827_1003 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/books/frankenstein.txt._COPYING_
2021-06-16 16:02:58,533 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop/books/frankenstein.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1804992934_1
2021-06-16 16:06:31,991 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 27 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 5 Number of syncs: 18 SyncTimes(ms): 22 
2021-06-16 16:24:38,142 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-16 16:24:38,144 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-master/10.128.0.9
************************************************************/
2021-06-16 16:27:43,545 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-master/10.128.0.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-kms-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn:/home/hadoop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-06-16 16:27:43,556 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-16 16:27:43,684 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-16 16:27:43,944 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-16 16:27:44,083 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-16 16:27:44,083 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-16 16:27:44,110 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://node-master:9000
2021-06-16 16:27:44,110 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use node-master:9000 to access this namenode/service.
2021-06-16 16:27:44,288 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-06-16 16:27:44,317 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2021-06-16 16:27:44,331 INFO org.eclipse.jetty.util.log: Logging initialized @1319ms
2021-06-16 16:27:44,428 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-16 16:27:44,442 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-16 16:27:44,449 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-16 16:27:44,453 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-16 16:27:44,453 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-16 16:27:44,453 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-16 16:27:44,482 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-16 16:27:44,482 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-16 16:27:44,495 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2021-06-16 16:27:44,496 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2021-06-16 16:27:44,525 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,AVAILABLE}
2021-06-16 16:27:44,526 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-06-16 16:27:44,598 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@13bc8645{/,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2021-06-16 16:27:44,604 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 16:27:44,604 INFO org.eclipse.jetty.server.Server: Started @1592ms
2021-06-16 16:27:44,909 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 16:27:44,909 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 16:27:44,910 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 16:27:44,910 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 16:27:44,916 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 16:27:44,916 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 16:27:44,960 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2021-06-16 16:27:44,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2021-06-16 16:27:44,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2021-06-16 16:27:44,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2021-06-16 16:27:44,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)
2021-06-16 16:27:44,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-16 16:27:44,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-16 16:27:44,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-16 16:27:45,032 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-06-16 16:27:45,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2021-06-16 16:27:45,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-16 16:27:45,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-16 16:27:45,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 16 16:27:45
2021-06-16 16:27:45,054 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-16 16:27:45,054 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 16:27:45,055 INFO org.apache.hadoop.util.GSet: 2.0% max memory 843 MB = 16.9 MB
2021-06-16 16:27:45,055 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-16 16:27:45,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2021-06-16 16:27:45,074 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-16 16:27:45,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-16 16:27:45,106 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2021-06-16 16:27:45,127 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-16 16:27:45,127 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 16:27:45,127 INFO org.apache.hadoop.util.GSet: 1.0% max memory 843 MB = 8.4 MB
2021-06-16 16:27:45,127 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-16 16:27:45,129 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-16 16:27:45,129 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2021-06-16 16:27:45,129 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-16 16:27:45,129 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2021-06-16 16:27:45,136 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2021-06-16 16:27:45,140 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2021-06-16 16:27:45,146 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-16 16:27:45,146 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 16:27:45,146 INFO org.apache.hadoop.util.GSet: 0.25% max memory 843 MB = 2.1 MB
2021-06-16 16:27:45,146 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-16 16:27:45,167 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-16 16:27:45,167 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-16 16:27:45,167 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-16 16:27:45,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-16 16:27:45,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-16 16:27:45,185 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-16 16:27:45,185 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 16:27:45,186 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 843 MB = 259.0 KB
2021-06-16 16:27:45,186 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-16 16:27:45,201 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hadoop/data/nameNode/in_use.lock acquired by nodename 7463@node-master
2021-06-16 16:27:45,254 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hadoop/data/nameNode/current
2021-06-16 16:27:45,300 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000006 -> /home/hadoop/data/nameNode/current/edits_0000000000000000006-0000000000000000032
2021-06-16 16:27:45,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000005, cpktTxId=0000000000000000005)
2021-06-16 16:27:45,461 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-06-16 16:27:45,507 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-16 16:27:45,507 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 5 from /home/hadoop/data/nameNode/current/fsimage_0000000000000000005
2021-06-16 16:27:45,507 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@35d08e6c expecting start txid #6
2021-06-16 16:27:45,508 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000006-0000000000000000032 maxTxnsToRead = 9223372036854775807
2021-06-16 16:27:45,510 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000006-0000000000000000032' to transaction ID 6
2021-06-16 16:27:45,659 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000006-0000000000000000032 of size 1048576 edits # 27 loaded in 0 seconds
2021-06-16 16:27:45,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-16 16:27:45,671 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 33
2021-06-16 16:27:45,956 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-16 16:27:45,956 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 765 msecs
2021-06-16 16:27:46,278 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-master:9000
2021-06-16 16:27:46,318 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2021-06-16 16:27:46,338 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-16 16:27:46,597 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2021-06-16 16:27:46,598 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 16:27:46,667 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-16 16:27:46,767 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-16 16:27:46,876 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-16 16:27:46,888 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-16 16:27:46,980 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-master/10.128.0.9:9000
2021-06-16 16:27:46,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-16 16:27:46,984 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2021-06-16 16:27:46,988 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=12
storage space=1230564
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2021-06-16 16:27:46,994 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-16 16:27:48,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 16:27:48,858 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.11:9866
2021-06-16 16:27:48,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d1ed285d-20a6-4d30-888b-6dc1293d773f (10.128.0.11:9866).
2021-06-16 16:27:48,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 16:27:48,868 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.10:9866
2021-06-16 16:27:48,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 2e312f92-a5b9-43a0-9f20-c2777806fca7 (10.128.0.10:9866).
2021-06-16 16:27:49,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6755ed7e-46ab-49db-a914-70207b487e68 for DN 10.128.0.11:9866
2021-06-16 16:27:49,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-e513b6ec-517f-4438-bd91-31af0d185455 for DN 10.128.0.10:9866
2021-06-16 16:27:49,370 INFO BlockStateChange: BLOCK* processReport 0x4ffca3290f759080: Processing first storage report for DS-e513b6ec-517f-4438-bd91-31af0d185455 from datanode 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 16:27:49,371 INFO BlockStateChange: BLOCK* processReport 0x4ffca3290f759080: from storage DS-e513b6ec-517f-4438-bd91-31af0d185455 node DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 16:27:49,371 INFO BlockStateChange: BLOCK* processReport 0xf6502fbe08a0d5a0: Processing first storage report for DS-6755ed7e-46ab-49db-a914-70207b487e68 from datanode d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 16:27:49,371 INFO BlockStateChange: BLOCK* processReport 0xf6502fbe08a0d5a0: from storage DS-6755ed7e-46ab-49db-a914-70207b487e68 node DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2021-06-16 16:27:50,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 16:27:50,480 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.9:9866
2021-06-16 16:27:50,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 108100fe-7661-4e2c-8041-5d1d21d2cc03 (10.128.0.9:9866).
2021-06-16 16:27:50,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 for DN 10.128.0.9:9866
2021-06-16 16:27:50,609 INFO BlockStateChange: BLOCK* processReport 0x7ce730b627e390b5: Processing first storage report for DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 from datanode 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 16:27:50,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2021-06-16 16:27:50,619 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 2 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-16 16:27:50,621 INFO BlockStateChange: BLOCK* processReport 0x7ce730b627e390b5: from storage DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 node DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 3, hasStaleStorage: false, processing time: 12 msecs, invalidatedBlocks: 0
2021-06-16 16:27:50,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 3
2021-06-16 16:27:50,659 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-16 16:27:50,659 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-16 16:27:50,659 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-16 16:27:50,659 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-16 16:27:50,659 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 23 msec
2021-06-16 16:28:10,632 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 3 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-16 16:28:20,641 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-16 16:28:20,642 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 33 secs
2021-06-16 16:28:20,642 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2021-06-16 16:28:20,642 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-16 16:28:52,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.128.0.9
2021-06-16 16:28:52,912 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-16 16:28:52,912 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 33, 33
2021-06-16 16:28:52,913 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 32 Number of syncs: 2 SyncTimes(ms): 36 
2021-06-16 16:28:52,914 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 32 Number of syncs: 3 SyncTimes(ms): 37 
2021-06-16 16:28:52,915 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000033 -> /home/hadoop/data/nameNode/current/edits_0000000000000000033-0000000000000000034
2021-06-16 16:28:52,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 35
2021-06-16 16:28:53,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/fsimage_0000000000000000005, fileSize: 393. Sent total: 393 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 16:28:53,321 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000006-0000000000000000032, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 16:28:53,341 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000033-0000000000000000034, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 16:28:53,825 INFO org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 1000.00 KB/s. Synchronous (fsync) write to disk of /home/hadoop/data/nameNode/current/fsimage.ckpt_0000000000000000034 took 0.00s.
2021-06-16 16:28:53,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000034 size 1153 bytes.
2021-06-16 16:28:53,831 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5
2021-06-16 16:28:53,831 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2021-06-16 16:30:04,574 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-16 16:30:04,577 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-master/10.128.0.9
************************************************************/
2021-06-16 17:01:29,957 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-master/34.134.172.99
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-kms-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn:/home/hadoop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-06-16 17:01:29,974 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-16 17:01:30,093 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-16 17:01:30,365 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-16 17:01:30,506 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-16 17:01:30,506 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-16 17:01:30,532 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://node-master:9000
2021-06-16 17:01:30,533 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use node-master:9000 to access this namenode/service.
2021-06-16 17:01:30,695 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-06-16 17:01:30,723 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2021-06-16 17:01:30,737 INFO org.eclipse.jetty.util.log: Logging initialized @1293ms
2021-06-16 17:01:30,839 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-16 17:01:30,852 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-16 17:01:30,858 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-16 17:01:30,860 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-16 17:01:30,860 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-16 17:01:30,860 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-16 17:01:30,885 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-16 17:01:30,885 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-16 17:01:30,897 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2021-06-16 17:01:30,898 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2021-06-16 17:01:30,938 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,AVAILABLE}
2021-06-16 17:01:30,939 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-06-16 17:01:31,030 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@13bc8645{/,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2021-06-16 17:01:31,037 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 17:01:31,037 INFO org.eclipse.jetty.server.Server: Started @1593ms
2021-06-16 17:01:31,373 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:01:31,374 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:01:31,374 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:01:31,374 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:01:31,379 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:01:31,380 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:01:31,422 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2021-06-16 17:01:31,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2021-06-16 17:01:31,436 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2021-06-16 17:01:31,437 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2021-06-16 17:01:31,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)
2021-06-16 17:01:31,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-16 17:01:31,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-16 17:01:31,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-16 17:01:31,489 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-06-16 17:01:31,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2021-06-16 17:01:31,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-16 17:01:31,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-16 17:01:31,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 16 17:01:31
2021-06-16 17:01:31,508 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-16 17:01:31,508 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:01:31,510 INFO org.apache.hadoop.util.GSet: 2.0% max memory 843 MB = 16.9 MB
2021-06-16 17:01:31,510 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-16 17:01:31,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2021-06-16 17:01:31,528 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2021-06-16 17:01:31,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-16 17:01:31,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2021-06-16 17:01:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2021-06-16 17:01:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-16 17:01:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-16 17:01:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-16 17:01:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-16 17:01:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2021-06-16 17:01:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-16 17:01:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-16 17:01:31,569 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2021-06-16 17:01:31,594 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-16 17:01:31,594 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:01:31,594 INFO org.apache.hadoop.util.GSet: 1.0% max memory 843 MB = 8.4 MB
2021-06-16 17:01:31,594 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-16 17:01:31,596 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-16 17:01:31,596 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2021-06-16 17:01:31,596 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-16 17:01:31,597 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2021-06-16 17:01:31,603 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2021-06-16 17:01:31,613 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2021-06-16 17:01:31,619 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-16 17:01:31,619 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:01:31,619 INFO org.apache.hadoop.util.GSet: 0.25% max memory 843 MB = 2.1 MB
2021-06-16 17:01:31,619 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-16 17:01:31,637 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-16 17:01:31,637 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-16 17:01:31,637 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-16 17:01:31,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-16 17:01:31,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-16 17:01:31,650 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-16 17:01:31,650 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:01:31,650 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 843 MB = 259.0 KB
2021-06-16 17:01:31,650 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-16 17:01:31,662 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hadoop/data/nameNode/in_use.lock acquired by nodename 9049@node-master
2021-06-16 17:01:31,689 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hadoop/data/nameNode/current
2021-06-16 17:01:31,722 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000035 -> /home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035
2021-06-16 17:01:31,770 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000034, cpktTxId=0000000000000000034)
2021-06-16 17:01:31,876 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 12 INodes.
2021-06-16 17:01:31,944 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-16 17:01:31,944 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 34 from /home/hadoop/data/nameNode/current/fsimage_0000000000000000034
2021-06-16 17:01:31,944 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@35d08e6c expecting start txid #35
2021-06-16 17:01:31,944 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035 maxTxnsToRead = 9223372036854775807
2021-06-16 17:01:31,946 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035' to transaction ID 35
2021-06-16 17:01:31,969 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-16 17:01:31,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-16 17:01:31,971 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 36
2021-06-16 17:01:32,158 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-16 17:01:32,158 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 505 msecs
2021-06-16 17:01:32,461 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-master:9000
2021-06-16 17:01:32,473 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2021-06-16 17:01:32,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for active state
2021-06-16 17:01:32,486 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 36, 36
2021-06-16 17:01:32,505 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 35 Number of syncs: 3 SyncTimes(ms): 28 
2021-06-16 17:01:32,506 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000036 -> /home/hadoop/data/nameNode/current/edits_0000000000000000036-0000000000000000037
2021-06-16 17:01:32,508 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: FSEditLogAsync was interrupted, exiting
2021-06-16 17:01:32,540 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for active state
2021-06-16 17:01:32,541 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2021-06-16 17:01:32,559 INFO org.eclipse.jetty.server.handler.ContextHandler: Stopped o.e.j.w.WebAppContext@13bc8645{/,null,UNAVAILABLE}{/hdfs}
2021-06-16 17:01:32,564 INFO org.eclipse.jetty.server.AbstractConnector: Stopped ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 17:01:32,576 INFO org.eclipse.jetty.server.handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,UNAVAILABLE}
2021-06-16 17:01:32,576 INFO org.eclipse.jetty.server.handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,UNAVAILABLE}
2021-06-16 17:01:32,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2021-06-16 17:01:32,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2021-06-16 17:01:32,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2021-06-16 17:01:32,641 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
java.net.BindException: Problem binding to [node-master:9000] java.net.BindException: Cannot assign requested address; For more details see:  http://wiki.apache.org/hadoop/BindException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:736)
	at org.apache.hadoop.ipc.Server.bind(Server.java:562)
	at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1038)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:2810)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:960)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.<init>(ProtobufRpcEngine.java:421)
	at org.apache.hadoop.ipc.ProtobufRpcEngine.getServer(ProtobufRpcEngine.java:342)
	at org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:802)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:457)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:783)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:697)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:937)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:910)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1643)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1710)
Caused by: java.net.BindException: Cannot assign requested address
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:461)
	at sun.nio.ch.Net.bind(Net.java:453)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:222)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:85)
	at org.apache.hadoop.ipc.Server.bind(Server.java:545)
	... 13 more
2021-06-16 17:01:32,644 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1: java.net.BindException: Problem binding to [node-master:9000] java.net.BindException: Cannot assign requested address; For more details see:  http://wiki.apache.org/hadoop/BindException
2021-06-16 17:01:32,694 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-master/34.134.172.99
************************************************************/
2021-06-16 17:07:13,848 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-master/10.128.0.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-kms-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn:/home/hadoop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-06-16 17:07:13,864 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-16 17:07:13,987 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-16 17:07:14,262 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-16 17:07:14,405 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-16 17:07:14,405 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-16 17:07:14,431 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://node-master:9000
2021-06-16 17:07:14,431 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use node-master:9000 to access this namenode/service.
2021-06-16 17:07:14,620 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-06-16 17:07:14,651 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2021-06-16 17:07:14,664 INFO org.eclipse.jetty.util.log: Logging initialized @1331ms
2021-06-16 17:07:14,769 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-16 17:07:14,780 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-16 17:07:14,785 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-16 17:07:14,788 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-16 17:07:14,788 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-16 17:07:14,788 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-16 17:07:14,813 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-16 17:07:14,813 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-16 17:07:14,825 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2021-06-16 17:07:14,826 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2021-06-16 17:07:14,870 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,AVAILABLE}
2021-06-16 17:07:14,871 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-06-16 17:07:14,952 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@13bc8645{/,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2021-06-16 17:07:14,960 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 17:07:14,961 INFO org.eclipse.jetty.server.Server: Started @1628ms
2021-06-16 17:07:15,259 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:07:15,259 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:07:15,260 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:07:15,260 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:07:15,266 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:07:15,266 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:07:15,310 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2021-06-16 17:07:15,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2021-06-16 17:07:15,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2021-06-16 17:07:15,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2021-06-16 17:07:15,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)
2021-06-16 17:07:15,328 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-16 17:07:15,328 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-16 17:07:15,328 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-16 17:07:15,374 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-06-16 17:07:15,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2021-06-16 17:07:15,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-16 17:07:15,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-16 17:07:15,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 16 17:07:15
2021-06-16 17:07:15,393 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-16 17:07:15,393 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:07:15,395 INFO org.apache.hadoop.util.GSet: 2.0% max memory 843 MB = 16.9 MB
2021-06-16 17:07:15,395 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-16 17:07:15,404 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2021-06-16 17:07:15,414 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-16 17:07:15,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-16 17:07:15,447 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2021-06-16 17:07:15,467 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-16 17:07:15,467 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:07:15,467 INFO org.apache.hadoop.util.GSet: 1.0% max memory 843 MB = 8.4 MB
2021-06-16 17:07:15,467 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-16 17:07:15,469 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-16 17:07:15,469 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2021-06-16 17:07:15,469 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-16 17:07:15,470 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2021-06-16 17:07:15,476 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2021-06-16 17:07:15,479 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2021-06-16 17:07:15,485 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-16 17:07:15,485 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:07:15,485 INFO org.apache.hadoop.util.GSet: 0.25% max memory 843 MB = 2.1 MB
2021-06-16 17:07:15,485 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-16 17:07:15,494 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-16 17:07:15,494 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-16 17:07:15,495 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-16 17:07:15,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-16 17:07:15,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-16 17:07:15,501 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-16 17:07:15,501 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:07:15,502 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 843 MB = 259.0 KB
2021-06-16 17:07:15,502 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-16 17:07:15,529 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hadoop/data/nameNode/in_use.lock acquired by nodename 21117@node-master
2021-06-16 17:07:15,563 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hadoop/data/nameNode/current
2021-06-16 17:07:15,572 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000034, cpktTxId=0000000000000000034)
2021-06-16 17:07:15,694 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 12 INodes.
2021-06-16 17:07:15,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-16 17:07:15,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 34 from /home/hadoop/data/nameNode/current/fsimage_0000000000000000034
2021-06-16 17:07:15,749 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2cc44ad expecting start txid #35
2021-06-16 17:07:15,749 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035 maxTxnsToRead = 9223372036854775807
2021-06-16 17:07:15,776 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035' to transaction ID 35
2021-06-16 17:07:15,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-16 17:07:15,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@44b3606b expecting start txid #36
2021-06-16 17:07:15,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000036-0000000000000000037 maxTxnsToRead = 9223372036854775807
2021-06-16 17:07:15,823 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000036-0000000000000000037' to transaction ID 35
2021-06-16 17:07:15,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000036-0000000000000000037 of size 42 edits # 2 loaded in 0 seconds
2021-06-16 17:07:15,824 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-16 17:07:15,825 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 38
2021-06-16 17:07:16,029 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-16 17:07:16,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 525 msecs
2021-06-16 17:07:16,252 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-master:9000
2021-06-16 17:07:16,265 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2021-06-16 17:07:16,282 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-16 17:07:16,561 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2021-06-16 17:07:16,566 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:07:16,576 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-16 17:07:16,595 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-16 17:07:16,660 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-16 17:07:16,664 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-16 17:07:16,669 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-master/10.128.0.9:9000
2021-06-16 17:07:16,696 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-16 17:07:16,697 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2021-06-16 17:07:16,706 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 9 milliseconds
name space=12
storage space=1230564
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2021-06-16 17:07:16,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-16 17:07:26,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 17:07:26,053 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.9:9866
2021-06-16 17:07:26,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 108100fe-7661-4e2c-8041-5d1d21d2cc03 (10.128.0.9:9866).
2021-06-16 17:07:26,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 for DN 10.128.0.9:9866
2021-06-16 17:07:26,150 INFO BlockStateChange: BLOCK* processReport 0x2a4592e695ddccb6: Processing first storage report for DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 from datanode 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 17:07:26,154 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2021-06-16 17:07:26,155 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 2 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-16 17:07:26,156 INFO BlockStateChange: BLOCK* processReport 0x2a4592e695ddccb6: from storage DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 node DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 3, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2021-06-16 17:07:26,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 3
2021-06-16 17:07:26,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-16 17:07:26,163 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-16 17:07:26,163 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-16 17:07:26,163 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-16 17:07:26,163 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2021-06-16 17:07:30,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 17:07:30,044 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.10:9866
2021-06-16 17:07:30,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 2e312f92-a5b9-43a0-9f20-c2777806fca7 (10.128.0.10:9866).
2021-06-16 17:07:30,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-e513b6ec-517f-4438-bd91-31af0d185455 for DN 10.128.0.10:9866
2021-06-16 17:07:30,101 INFO BlockStateChange: BLOCK* processReport 0xdfc7f29f57de273: Processing first storage report for DS-e513b6ec-517f-4438-bd91-31af0d185455 from datanode 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 17:07:30,102 INFO BlockStateChange: BLOCK* processReport 0xdfc7f29f57de273: from storage DS-e513b6ec-517f-4438-bd91-31af0d185455 node DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2021-06-16 17:07:30,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 17:07:30,128 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.11:9866
2021-06-16 17:07:30,128 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d1ed285d-20a6-4d30-888b-6dc1293d773f (10.128.0.11:9866).
2021-06-16 17:07:30,176 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6755ed7e-46ab-49db-a914-70207b487e68 for DN 10.128.0.11:9866
2021-06-16 17:07:30,207 INFO BlockStateChange: BLOCK* processReport 0x9f89284e2fe2eefc: Processing first storage report for DS-6755ed7e-46ab-49db-a914-70207b487e68 from datanode d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 17:07:30,207 INFO BlockStateChange: BLOCK* processReport 0x9f89284e2fe2eefc: from storage DS-6755ed7e-46ab-49db-a914-70207b487e68 node DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2021-06-16 17:07:42,967 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-16 17:07:42,969 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-master/10.128.0.9
************************************************************/
2021-06-16 17:08:03,966 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-master/10.128.0.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-kms-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn:/home/hadoop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-06-16 17:08:03,983 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-16 17:08:04,111 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-16 17:08:04,380 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-16 17:08:04,525 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-16 17:08:04,526 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-16 17:08:04,551 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://node-master:9000
2021-06-16 17:08:04,551 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use node-master:9000 to access this namenode/service.
2021-06-16 17:08:04,744 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-06-16 17:08:04,818 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2021-06-16 17:08:04,831 INFO org.eclipse.jetty.util.log: Logging initialized @1377ms
2021-06-16 17:08:04,936 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-16 17:08:04,950 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-16 17:08:04,955 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-16 17:08:04,957 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-16 17:08:04,957 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-16 17:08:04,958 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-16 17:08:04,985 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-16 17:08:04,985 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-16 17:08:04,996 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2021-06-16 17:08:04,998 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2021-06-16 17:08:05,033 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,AVAILABLE}
2021-06-16 17:08:05,033 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-06-16 17:08:05,121 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@13bc8645{/,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2021-06-16 17:08:05,128 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 17:08:05,128 INFO org.eclipse.jetty.server.Server: Started @1675ms
2021-06-16 17:08:05,447 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:08:05,448 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:08:05,448 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:08:05,448 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:08:05,455 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:08:05,455 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:08:05,511 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2021-06-16 17:08:05,526 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2021-06-16 17:08:05,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2021-06-16 17:08:05,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2021-06-16 17:08:05,535 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)
2021-06-16 17:08:05,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-16 17:08:05,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-16 17:08:05,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-16 17:08:05,583 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-06-16 17:08:05,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2021-06-16 17:08:05,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-16 17:08:05,600 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-16 17:08:05,600 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 16 17:08:05
2021-06-16 17:08:05,605 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-16 17:08:05,605 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:08:05,607 INFO org.apache.hadoop.util.GSet: 2.0% max memory 843 MB = 16.9 MB
2021-06-16 17:08:05,607 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-16 17:08:05,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2021-06-16 17:08:05,637 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-16 17:08:05,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-16 17:08:05,676 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2021-06-16 17:08:05,692 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-16 17:08:05,692 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:08:05,693 INFO org.apache.hadoop.util.GSet: 1.0% max memory 843 MB = 8.4 MB
2021-06-16 17:08:05,693 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-16 17:08:05,694 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-16 17:08:05,695 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2021-06-16 17:08:05,695 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-16 17:08:05,695 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2021-06-16 17:08:05,701 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2021-06-16 17:08:05,704 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2021-06-16 17:08:05,710 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-16 17:08:05,710 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:08:05,710 INFO org.apache.hadoop.util.GSet: 0.25% max memory 843 MB = 2.1 MB
2021-06-16 17:08:05,710 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-16 17:08:05,720 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-16 17:08:05,720 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-16 17:08:05,720 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-16 17:08:05,724 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-16 17:08:05,724 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-16 17:08:05,727 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-16 17:08:05,727 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:08:05,727 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 843 MB = 259.0 KB
2021-06-16 17:08:05,727 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-16 17:08:05,752 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hadoop/data/nameNode/in_use.lock acquired by nodename 22196@node-master
2021-06-16 17:08:05,779 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hadoop/data/nameNode/current
2021-06-16 17:08:05,824 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000038 -> /home/hadoop/data/nameNode/current/edits_0000000000000000038-0000000000000000038
2021-06-16 17:08:05,880 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000034, cpktTxId=0000000000000000034)
2021-06-16 17:08:05,967 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 12 INodes.
2021-06-16 17:08:06,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-16 17:08:06,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 34 from /home/hadoop/data/nameNode/current/fsimage_0000000000000000034
2021-06-16 17:08:06,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@35d08e6c expecting start txid #35
2021-06-16 17:08:06,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035 maxTxnsToRead = 9223372036854775807
2021-06-16 17:08:06,020 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035' to transaction ID 35
2021-06-16 17:08:06,035 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-16 17:08:06,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@53d102a2 expecting start txid #36
2021-06-16 17:08:06,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000036-0000000000000000037 maxTxnsToRead = 9223372036854775807
2021-06-16 17:08:06,036 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000036-0000000000000000037' to transaction ID 35
2021-06-16 17:08:06,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000036-0000000000000000037 of size 42 edits # 2 loaded in 0 seconds
2021-06-16 17:08:06,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6c45ee6e expecting start txid #38
2021-06-16 17:08:06,036 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000038-0000000000000000038 maxTxnsToRead = 9223372036854775807
2021-06-16 17:08:06,036 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000038-0000000000000000038' to transaction ID 35
2021-06-16 17:08:06,037 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000038-0000000000000000038 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-16 17:08:06,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-16 17:08:06,050 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 39
2021-06-16 17:08:06,235 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-16 17:08:06,235 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 505 msecs
2021-06-16 17:08:06,538 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-master:9000
2021-06-16 17:08:06,561 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2021-06-16 17:08:06,584 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-16 17:08:06,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2021-06-16 17:08:06,850 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:08:06,894 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-16 17:08:07,000 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-16 17:08:07,111 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-16 17:08:07,129 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-16 17:08:07,197 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-master/10.128.0.9:9000
2021-06-16 17:08:07,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-16 17:08:07,201 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2021-06-16 17:08:07,208 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 7 milliseconds
name space=12
storage space=1230564
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2021-06-16 17:08:07,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-16 17:08:09,386 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 17:08:09,387 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.11:9866
2021-06-16 17:08:09,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d1ed285d-20a6-4d30-888b-6dc1293d773f (10.128.0.11:9866).
2021-06-16 17:08:09,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 17:08:09,397 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.10:9866
2021-06-16 17:08:09,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 2e312f92-a5b9-43a0-9f20-c2777806fca7 (10.128.0.10:9866).
2021-06-16 17:08:09,620 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6755ed7e-46ab-49db-a914-70207b487e68 for DN 10.128.0.11:9866
2021-06-16 17:08:09,939 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-e513b6ec-517f-4438-bd91-31af0d185455 for DN 10.128.0.10:9866
2021-06-16 17:08:09,969 INFO BlockStateChange: BLOCK* processReport 0x62c98fa5304faa7f: Processing first storage report for DS-6755ed7e-46ab-49db-a914-70207b487e68 from datanode d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 17:08:09,970 INFO BlockStateChange: BLOCK* processReport 0x62c98fa5304faa7f: from storage DS-6755ed7e-46ab-49db-a914-70207b487e68 node DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 17:08:09,985 INFO BlockStateChange: BLOCK* processReport 0xfb62e700f7f4edd5: Processing first storage report for DS-e513b6ec-517f-4438-bd91-31af0d185455 from datanode 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 17:08:09,985 INFO BlockStateChange: BLOCK* processReport 0xfb62e700f7f4edd5: from storage DS-e513b6ec-517f-4438-bd91-31af0d185455 node DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2021-06-16 17:08:11,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 17:08:11,516 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.9:9866
2021-06-16 17:08:11,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 108100fe-7661-4e2c-8041-5d1d21d2cc03 (10.128.0.9:9866).
2021-06-16 17:08:11,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 for DN 10.128.0.9:9866
2021-06-16 17:08:11,851 INFO BlockStateChange: BLOCK* processReport 0x238216fa1eea0caf: Processing first storage report for DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 from datanode 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 17:08:11,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2021-06-16 17:08:11,879 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 2 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-16 17:08:11,881 INFO BlockStateChange: BLOCK* processReport 0x238216fa1eea0caf: from storage DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 node DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 3, hasStaleStorage: false, processing time: 30 msecs, invalidatedBlocks: 0
2021-06-16 17:08:11,906 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 3
2021-06-16 17:08:11,906 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-16 17:08:11,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-16 17:08:11,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-16 17:08:11,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-16 17:08:11,907 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 25 msec
2021-06-16 17:08:31,929 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 3 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-16 17:08:41,931 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-16 17:08:41,932 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 34 secs
2021-06-16 17:08:41,932 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2021-06-16 17:08:41,932 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-16 17:09:13,997 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.128.0.9
2021-06-16 17:09:13,997 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-16 17:09:13,997 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 39, 39
2021-06-16 17:09:13,998 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 38 Number of syncs: 2 SyncTimes(ms): 8 
2021-06-16 17:09:13,999 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 38 Number of syncs: 3 SyncTimes(ms): 9 
2021-06-16 17:09:14,000 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000039 -> /home/hadoop/data/nameNode/current/edits_0000000000000000039-0000000000000000040
2021-06-16 17:09:14,000 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 41
2021-06-16 17:09:14,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/fsimage_0000000000000000034, fileSize: 1153. Sent total: 1153 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:09:14,241 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000035-0000000000000000035, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:09:14,250 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000036-0000000000000000037, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:09:14,260 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000038-0000000000000000038, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:09:14,273 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000039-0000000000000000040, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:09:14,572 INFO org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 1000.00 KB/s. Synchronous (fsync) write to disk of /home/hadoop/data/nameNode/current/fsimage.ckpt_0000000000000000040 took 0.00s.
2021-06-16 17:09:14,572 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000040 size 1153 bytes.
2021-06-16 17:09:14,575 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 34
2021-06-16 17:09:14,575 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000005, cpktTxId=0000000000000000005)
2021-06-16 17:10:26,547 INFO BlockStateChange: BLOCK* processReport 0x238216fa1eea0cb0: from storage DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 node DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 3, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 17:34:25,143 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-16 17:34:25,146 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-master/10.128.0.9
************************************************************/
2021-06-16 17:37:46,625 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-master/10.128.0.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-kms-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn:/home/hadoop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-06-16 17:37:46,635 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-16 17:37:46,773 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-16 17:37:47,034 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-16 17:37:47,211 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-16 17:37:47,211 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-16 17:37:47,240 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://node-master:9000
2021-06-16 17:37:47,241 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use node-master:9000 to access this namenode/service.
2021-06-16 17:37:47,423 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-06-16 17:37:47,450 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2021-06-16 17:37:47,464 INFO org.eclipse.jetty.util.log: Logging initialized @1385ms
2021-06-16 17:37:47,563 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-16 17:37:47,573 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-16 17:37:47,578 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-16 17:37:47,581 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-16 17:37:47,581 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-16 17:37:47,581 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-16 17:37:47,606 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-16 17:37:47,606 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-16 17:37:47,617 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2021-06-16 17:37:47,618 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2021-06-16 17:37:47,664 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,AVAILABLE}
2021-06-16 17:37:47,665 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-06-16 17:37:47,749 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@13bc8645{/,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2021-06-16 17:37:47,756 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 17:37:47,756 INFO org.eclipse.jetty.server.Server: Started @1676ms
2021-06-16 17:37:48,095 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:37:48,096 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:37:48,096 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:37:48,096 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:37:48,103 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:37:48,103 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:37:48,179 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2021-06-16 17:37:48,195 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2021-06-16 17:37:48,196 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2021-06-16 17:37:48,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2021-06-16 17:37:48,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)
2021-06-16 17:37:48,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-16 17:37:48,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-16 17:37:48,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-16 17:37:48,266 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-06-16 17:37:48,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2021-06-16 17:37:48,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-16 17:37:48,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-16 17:37:48,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 16 17:37:48
2021-06-16 17:37:48,286 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-16 17:37:48,286 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:37:48,288 INFO org.apache.hadoop.util.GSet: 2.0% max memory 843 MB = 16.9 MB
2021-06-16 17:37:48,288 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-16 17:37:48,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2021-06-16 17:37:48,305 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-16 17:37:48,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-16 17:37:48,335 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2021-06-16 17:37:48,365 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-16 17:37:48,365 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:37:48,365 INFO org.apache.hadoop.util.GSet: 1.0% max memory 843 MB = 8.4 MB
2021-06-16 17:37:48,365 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-16 17:37:48,367 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-16 17:37:48,367 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2021-06-16 17:37:48,367 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-16 17:37:48,367 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2021-06-16 17:37:48,373 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2021-06-16 17:37:48,375 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2021-06-16 17:37:48,380 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-16 17:37:48,380 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:37:48,380 INFO org.apache.hadoop.util.GSet: 0.25% max memory 843 MB = 2.1 MB
2021-06-16 17:37:48,381 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-16 17:37:48,388 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-16 17:37:48,388 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-16 17:37:48,388 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-16 17:37:48,391 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-16 17:37:48,391 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-16 17:37:48,394 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-16 17:37:48,394 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:37:48,394 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 843 MB = 259.0 KB
2021-06-16 17:37:48,394 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-16 17:37:48,409 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hadoop/data/nameNode/in_use.lock acquired by nodename 24500@node-master
2021-06-16 17:37:48,448 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hadoop/data/nameNode/current
2021-06-16 17:37:48,486 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000041 -> /home/hadoop/data/nameNode/current/edits_0000000000000000041-0000000000000000041
2021-06-16 17:37:48,520 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000040, cpktTxId=0000000000000000040)
2021-06-16 17:37:48,633 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 12 INodes.
2021-06-16 17:37:48,682 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-16 17:37:48,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 40 from /home/hadoop/data/nameNode/current/fsimage_0000000000000000040
2021-06-16 17:37:48,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6c45ee6e expecting start txid #41
2021-06-16 17:37:48,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000041-0000000000000000041 maxTxnsToRead = 9223372036854775807
2021-06-16 17:37:48,685 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000041-0000000000000000041' to transaction ID 41
2021-06-16 17:37:48,703 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000041-0000000000000000041 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-16 17:37:48,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-16 17:37:48,705 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 42
2021-06-16 17:37:48,984 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-16 17:37:48,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 587 msecs
2021-06-16 17:37:49,367 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-master:9000
2021-06-16 17:37:49,383 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2021-06-16 17:37:49,398 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-16 17:37:49,679 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2021-06-16 17:37:49,681 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:37:49,694 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-16 17:37:49,708 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-16 17:37:49,768 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-16 17:37:49,770 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-16 17:37:49,772 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-master/10.128.0.9:9000
2021-06-16 17:37:49,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-16 17:37:49,776 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2021-06-16 17:37:49,795 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 19 milliseconds
name space=12
storage space=1230564
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2021-06-16 17:37:49,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-16 17:37:51,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 17:37:51,880 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.10:9866
2021-06-16 17:37:51,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 2e312f92-a5b9-43a0-9f20-c2777806fca7 (10.128.0.10:9866).
2021-06-16 17:37:51,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 17:37:51,917 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.11:9866
2021-06-16 17:37:51,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d1ed285d-20a6-4d30-888b-6dc1293d773f (10.128.0.11:9866).
2021-06-16 17:37:52,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-e513b6ec-517f-4438-bd91-31af0d185455 for DN 10.128.0.10:9866
2021-06-16 17:37:52,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6755ed7e-46ab-49db-a914-70207b487e68 for DN 10.128.0.11:9866
2021-06-16 17:37:52,366 INFO BlockStateChange: BLOCK* processReport 0x19473e56eb0cc68c: Processing first storage report for DS-6755ed7e-46ab-49db-a914-70207b487e68 from datanode d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 17:37:52,367 INFO BlockStateChange: BLOCK* processReport 0x19473e56eb0cc68c: from storage DS-6755ed7e-46ab-49db-a914-70207b487e68 node DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 17:37:52,367 INFO BlockStateChange: BLOCK* processReport 0x69c6050218f7add6: Processing first storage report for DS-e513b6ec-517f-4438-bd91-31af0d185455 from datanode 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 17:37:52,367 INFO BlockStateChange: BLOCK* processReport 0x69c6050218f7add6: from storage DS-e513b6ec-517f-4438-bd91-31af0d185455 node DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2021-06-16 17:37:54,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 17:37:54,154 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.9:9866
2021-06-16 17:37:54,154 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 108100fe-7661-4e2c-8041-5d1d21d2cc03 (10.128.0.9:9866).
2021-06-16 17:37:54,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 for DN 10.128.0.9:9866
2021-06-16 17:37:54,300 INFO BlockStateChange: BLOCK* processReport 0xde6d01e7c7cd906b: Processing first storage report for DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 from datanode 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 17:37:54,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2021-06-16 17:37:54,307 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 2 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2021-06-16 17:37:54,308 INFO BlockStateChange: BLOCK* processReport 0xde6d01e7c7cd906b: from storage DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 node DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 3, hasStaleStorage: false, processing time: 8 msecs, invalidatedBlocks: 0
2021-06-16 17:37:54,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 3
2021-06-16 17:37:54,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-16 17:37:54,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-16 17:37:54,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-16 17:37:54,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-16 17:37:54,353 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 32 msec
2021-06-16 17:38:14,347 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 3 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-16 17:38:24,350 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-16 17:38:24,350 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 34 secs
2021-06-16 17:38:24,350 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2021-06-16 17:38:24,350 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-16 17:38:56,383 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.128.0.9
2021-06-16 17:38:56,383 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-16 17:38:56,384 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 42, 42
2021-06-16 17:38:56,385 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 41 Number of syncs: 2 SyncTimes(ms): 15 
2021-06-16 17:38:56,387 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 41 Number of syncs: 3 SyncTimes(ms): 17 
2021-06-16 17:38:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000042 -> /home/hadoop/data/nameNode/current/edits_0000000000000000042-0000000000000000043
2021-06-16 17:38:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 44
2021-06-16 17:38:56,606 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/fsimage_0000000000000000040, fileSize: 1153. Sent total: 1153 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:38:56,635 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000041-0000000000000000041, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:38:56,647 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000042-0000000000000000043, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:38:56,953 INFO org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 1000.00 KB/s. Synchronous (fsync) write to disk of /home/hadoop/data/nameNode/current/fsimage.ckpt_0000000000000000043 took 0.00s.
2021-06-16 17:38:56,953 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000043 size 1153 bytes.
2021-06-16 17:38:56,957 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 40
2021-06-16 17:38:56,958 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000034, cpktTxId=0000000000000000034)
2021-06-16 17:40:20,412 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-16 17:40:20,415 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-master/10.128.0.9
************************************************************/
2021-06-16 17:49:40,765 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-master/10.128.0.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-kms-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn:/home/hadoop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-06-16 17:49:40,777 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-16 17:49:40,932 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-16 17:49:41,173 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-16 17:49:41,296 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-16 17:49:41,296 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-16 17:49:41,322 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://node-master:9000
2021-06-16 17:49:41,322 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use node-master:9000 to access this namenode/service.
2021-06-16 17:49:41,502 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-06-16 17:49:41,576 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2021-06-16 17:49:41,591 INFO org.eclipse.jetty.util.log: Logging initialized @1367ms
2021-06-16 17:49:41,686 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-16 17:49:41,699 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-16 17:49:41,704 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-16 17:49:41,707 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-16 17:49:41,707 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-16 17:49:41,707 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-16 17:49:41,734 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-16 17:49:41,734 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-16 17:49:41,744 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2021-06-16 17:49:41,745 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2021-06-16 17:49:41,773 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,AVAILABLE}
2021-06-16 17:49:41,774 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-06-16 17:49:41,838 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@13bc8645{/,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2021-06-16 17:49:41,845 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 17:49:41,845 INFO org.eclipse.jetty.server.Server: Started @1622ms
2021-06-16 17:49:42,156 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:49:42,157 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:49:42,157 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:49:42,157 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 17:49:42,163 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:49:42,163 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:49:42,207 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2021-06-16 17:49:42,222 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2021-06-16 17:49:42,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2021-06-16 17:49:42,225 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2021-06-16 17:49:42,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)
2021-06-16 17:49:42,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-16 17:49:42,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-16 17:49:42,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-16 17:49:42,301 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-06-16 17:49:42,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2021-06-16 17:49:42,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-16 17:49:42,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-16 17:49:42,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 16 17:49:42
2021-06-16 17:49:42,327 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-16 17:49:42,327 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:49:42,333 INFO org.apache.hadoop.util.GSet: 2.0% max memory 843 MB = 16.9 MB
2021-06-16 17:49:42,333 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-16 17:49:42,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2021-06-16 17:49:42,355 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2021-06-16 17:49:42,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-16 17:49:42,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2021-06-16 17:49:42,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2021-06-16 17:49:42,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-16 17:49:42,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-16 17:49:42,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-16 17:49:42,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-16 17:49:42,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2021-06-16 17:49:42,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-16 17:49:42,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-16 17:49:42,410 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2021-06-16 17:49:42,424 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-16 17:49:42,424 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:49:42,424 INFO org.apache.hadoop.util.GSet: 1.0% max memory 843 MB = 8.4 MB
2021-06-16 17:49:42,424 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-16 17:49:42,426 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-16 17:49:42,426 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2021-06-16 17:49:42,426 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-16 17:49:42,426 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2021-06-16 17:49:42,432 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2021-06-16 17:49:42,435 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2021-06-16 17:49:42,440 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-16 17:49:42,440 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:49:42,441 INFO org.apache.hadoop.util.GSet: 0.25% max memory 843 MB = 2.1 MB
2021-06-16 17:49:42,441 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-16 17:49:42,450 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-16 17:49:42,450 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-16 17:49:42,450 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-16 17:49:42,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-16 17:49:42,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-16 17:49:42,456 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-16 17:49:42,456 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 17:49:42,456 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 843 MB = 259.0 KB
2021-06-16 17:49:42,456 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-16 17:49:42,488 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hadoop/data/nameNode/in_use.lock acquired by nodename 26415@node-master
2021-06-16 17:49:42,516 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hadoop/data/nameNode/current
2021-06-16 17:49:42,548 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000044 -> /home/hadoop/data/nameNode/current/edits_0000000000000000044-0000000000000000044
2021-06-16 17:49:42,601 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2021-06-16 17:49:42,690 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 12 INodes.
2021-06-16 17:49:42,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-16 17:49:42,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 43 from /home/hadoop/data/nameNode/current/fsimage_0000000000000000043
2021-06-16 17:49:42,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6c45ee6e expecting start txid #44
2021-06-16 17:49:42,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000044-0000000000000000044 maxTxnsToRead = 9223372036854775807
2021-06-16 17:49:42,744 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000044-0000000000000000044' to transaction ID 44
2021-06-16 17:49:42,762 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000044-0000000000000000044 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-16 17:49:42,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-16 17:49:42,764 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 45
2021-06-16 17:49:42,985 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-16 17:49:42,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 526 msecs
2021-06-16 17:49:43,313 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-master:9000
2021-06-16 17:49:43,339 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2021-06-16 17:49:43,377 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-16 17:49:43,717 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2021-06-16 17:49:43,718 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 17:49:43,732 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-16 17:49:43,745 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-16 17:49:43,835 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-16 17:49:43,837 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-16 17:49:43,840 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-master/10.128.0.9:9000
2021-06-16 17:49:43,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-16 17:49:43,866 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2021-06-16 17:49:43,931 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 65 milliseconds
name space=12
storage space=1230564
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2021-06-16 17:49:44,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-16 17:49:45,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 17:49:45,836 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.11:9866
2021-06-16 17:49:45,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d1ed285d-20a6-4d30-888b-6dc1293d773f (10.128.0.11:9866).
2021-06-16 17:49:45,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 17:49:45,847 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.10:9866
2021-06-16 17:49:45,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 2e312f92-a5b9-43a0-9f20-c2777806fca7 (10.128.0.10:9866).
2021-06-16 17:49:46,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6755ed7e-46ab-49db-a914-70207b487e68 for DN 10.128.0.11:9866
2021-06-16 17:49:46,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-e513b6ec-517f-4438-bd91-31af0d185455 for DN 10.128.0.10:9866
2021-06-16 17:49:46,407 INFO BlockStateChange: BLOCK* processReport 0x2ae02a62c5fc6955: Processing first storage report for DS-6755ed7e-46ab-49db-a914-70207b487e68 from datanode d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 17:49:46,408 INFO BlockStateChange: BLOCK* processReport 0x2ae02a62c5fc6955: from storage DS-6755ed7e-46ab-49db-a914-70207b487e68 node DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 17:49:46,409 INFO BlockStateChange: BLOCK* processReport 0x7751d995f2b2cf03: Processing first storage report for DS-e513b6ec-517f-4438-bd91-31af0d185455 from datanode 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 17:49:46,409 INFO BlockStateChange: BLOCK* processReport 0x7751d995f2b2cf03: from storage DS-e513b6ec-517f-4438-bd91-31af0d185455 node DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 17:49:48,017 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 17:49:48,018 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.9:9866
2021-06-16 17:49:48,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 108100fe-7661-4e2c-8041-5d1d21d2cc03 (10.128.0.9:9866).
2021-06-16 17:49:48,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 for DN 10.128.0.9:9866
2021-06-16 17:49:48,133 INFO BlockStateChange: BLOCK* processReport 0x27d40e6136cd04e6: Processing first storage report for DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 from datanode 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 17:49:48,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2021-06-16 17:49:48,139 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 2 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-16 17:49:48,141 INFO BlockStateChange: BLOCK* processReport 0x27d40e6136cd04e6: from storage DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 node DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 3, hasStaleStorage: false, processing time: 8 msecs, invalidatedBlocks: 0
2021-06-16 17:49:48,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 3
2021-06-16 17:49:48,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-16 17:49:48,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-16 17:49:48,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-16 17:49:48,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-16 17:49:48,160 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2021-06-16 17:50:08,173 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 3 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-16 17:50:18,175 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-16 17:50:18,175 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 34 secs
2021-06-16 17:50:18,175 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2021-06-16 17:50:18,175 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-16 17:50:50,461 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.128.0.9
2021-06-16 17:50:50,461 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-16 17:50:50,461 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 45, 45
2021-06-16 17:50:50,461 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 44 Number of syncs: 2 SyncTimes(ms): 9 
2021-06-16 17:50:50,462 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 44 Number of syncs: 3 SyncTimes(ms): 10 
2021-06-16 17:50:50,463 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000045 -> /home/hadoop/data/nameNode/current/edits_0000000000000000045-0000000000000000046
2021-06-16 17:50:50,464 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 47
2021-06-16 17:50:50,644 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/fsimage_0000000000000000043, fileSize: 1153. Sent total: 1153 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:50:50,672 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000044-0000000000000000044, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:50:50,687 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000045-0000000000000000046, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 17:50:51,008 INFO org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 1000.00 KB/s. Synchronous (fsync) write to disk of /home/hadoop/data/nameNode/current/fsimage.ckpt_0000000000000000046 took 0.00s.
2021-06-16 17:50:51,008 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000046 size 1153 bytes.
2021-06-16 17:50:51,017 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 43
2021-06-16 17:50:51,017 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000040, cpktTxId=0000000000000000040)
2021-06-16 17:59:08,252 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-16 17:59:08,255 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-master/10.128.0.9
************************************************************/
2021-06-16 18:07:45,090 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-master/10.128.0.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /home/hadoop/hadoop/etc/hadoop:/home/hadoop/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/hadoop/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/common/hadoop-kms-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn:/home/hadoop/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/hadoop/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/home/hadoop/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-06-16 18:07:45,101 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-16 18:07:45,249 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-16 18:07:45,495 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-16 18:07:45,648 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-16 18:07:45,648 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-16 18:07:45,685 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://node-master:9000
2021-06-16 18:07:45,685 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use node-master:9000 to access this namenode/service.
2021-06-16 18:07:45,872 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-06-16 18:07:45,897 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2021-06-16 18:07:45,909 INFO org.eclipse.jetty.util.log: Logging initialized @1349ms
2021-06-16 18:07:46,004 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-16 18:07:46,017 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-16 18:07:46,022 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-16 18:07:46,025 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-16 18:07:46,025 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-16 18:07:46,025 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-16 18:07:46,049 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-16 18:07:46,049 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-16 18:07:46,059 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2021-06-16 18:07:46,060 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2021-06-16 18:07:46,091 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@239a307b{/logs,file:///home/hadoop/hadoop/logs/,AVAILABLE}
2021-06-16 18:07:46,091 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f204a1a{/static,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-06-16 18:07:46,158 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@13bc8645{/,file:///home/hadoop/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2021-06-16 18:07:46,164 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2021-06-16 18:07:46,164 INFO org.eclipse.jetty.server.Server: Started @1604ms
2021-06-16 18:07:46,477 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 18:07:46,477 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 18:07:46,478 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 18:07:46,478 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-16 18:07:46,483 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 18:07:46,483 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 18:07:46,527 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2021-06-16 18:07:46,541 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2021-06-16 18:07:46,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2021-06-16 18:07:46,544 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2021-06-16 18:07:46,550 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)
2021-06-16 18:07:46,550 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-16 18:07:46,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-16 18:07:46,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-16 18:07:46,597 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-06-16 18:07:46,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2021-06-16 18:07:46,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-16 18:07:46,613 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-16 18:07:46,613 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 16 18:07:46
2021-06-16 18:07:46,615 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-16 18:07:46,615 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 18:07:46,618 INFO org.apache.hadoop.util.GSet: 2.0% max memory 843 MB = 16.9 MB
2021-06-16 18:07:46,619 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-16 18:07:46,628 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2021-06-16 18:07:46,638 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2021-06-16 18:07:46,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-16 18:07:46,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2021-06-16 18:07:46,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2021-06-16 18:07:46,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-16 18:07:46,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-16 18:07:46,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-16 18:07:46,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-16 18:07:46,639 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2021-06-16 18:07:46,639 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-16 18:07:46,639 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-16 18:07:46,669 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
2021-06-16 18:07:46,689 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-16 18:07:46,689 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 18:07:46,689 INFO org.apache.hadoop.util.GSet: 1.0% max memory 843 MB = 8.4 MB
2021-06-16 18:07:46,689 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-16 18:07:46,691 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-16 18:07:46,691 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2021-06-16 18:07:46,691 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-16 18:07:46,691 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2021-06-16 18:07:46,697 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2021-06-16 18:07:46,700 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2021-06-16 18:07:46,706 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-16 18:07:46,706 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 18:07:46,706 INFO org.apache.hadoop.util.GSet: 0.25% max memory 843 MB = 2.1 MB
2021-06-16 18:07:46,706 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-16 18:07:46,716 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-16 18:07:46,717 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-16 18:07:46,717 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-16 18:07:46,722 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-16 18:07:46,722 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-16 18:07:46,724 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-16 18:07:46,725 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-16 18:07:46,725 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 843 MB = 259.0 KB
2021-06-16 18:07:46,725 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-16 18:07:46,749 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hadoop/data/nameNode/in_use.lock acquired by nodename 27717@node-master
2021-06-16 18:07:46,797 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hadoop/data/nameNode/current
2021-06-16 18:07:46,873 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000047 -> /home/hadoop/data/nameNode/current/edits_0000000000000000047-0000000000000000047
2021-06-16 18:07:46,922 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000046, cpktTxId=0000000000000000046)
2021-06-16 18:07:47,016 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 12 INodes.
2021-06-16 18:07:47,070 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-16 18:07:47,070 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 46 from /home/hadoop/data/nameNode/current/fsimage_0000000000000000046
2021-06-16 18:07:47,071 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6c45ee6e expecting start txid #47
2021-06-16 18:07:47,071 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/hadoop/data/nameNode/current/edits_0000000000000000047-0000000000000000047 maxTxnsToRead = 9223372036854775807
2021-06-16 18:07:47,073 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/home/hadoop/data/nameNode/current/edits_0000000000000000047-0000000000000000047' to transaction ID 47
2021-06-16 18:07:47,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/hadoop/data/nameNode/current/edits_0000000000000000047-0000000000000000047 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-16 18:07:47,091 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-16 18:07:47,094 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 48
2021-06-16 18:07:47,280 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-16 18:07:47,280 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 552 msecs
2021-06-16 18:07:47,529 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-master:9000
2021-06-16 18:07:47,543 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2021-06-16 18:07:47,559 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-16 18:07:47,839 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2021-06-16 18:07:47,840 INFO org.apache.hadoop.hdfs.server.common.Util: Assuming 'file' scheme for path /home/hadoop/data/nameNode in configuration.
2021-06-16 18:07:47,865 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-16 18:07:47,909 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-16 18:07:48,072 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-16 18:07:48,078 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-16 18:07:48,136 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-master/10.128.0.9:9000
2021-06-16 18:07:48,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-16 18:07:48,140 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2021-06-16 18:07:48,149 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 10 milliseconds
name space=12
storage space=1230564
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2021-06-16 18:07:48,154 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-16 18:07:50,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 18:07:50,362 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.10:9866
2021-06-16 18:07:50,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 2e312f92-a5b9-43a0-9f20-c2777806fca7 (10.128.0.10:9866).
2021-06-16 18:07:50,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 18:07:50,393 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.11:9866
2021-06-16 18:07:50,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d1ed285d-20a6-4d30-888b-6dc1293d773f (10.128.0.11:9866).
2021-06-16 18:07:50,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-e513b6ec-517f-4438-bd91-31af0d185455 for DN 10.128.0.10:9866
2021-06-16 18:07:50,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6755ed7e-46ab-49db-a914-70207b487e68 for DN 10.128.0.11:9866
2021-06-16 18:07:50,819 INFO BlockStateChange: BLOCK* processReport 0x3545369e0b47f7b5: Processing first storage report for DS-e513b6ec-517f-4438-bd91-31af0d185455 from datanode 2e312f92-a5b9-43a0-9f20-c2777806fca7
2021-06-16 18:07:50,820 INFO BlockStateChange: BLOCK* processReport 0x3545369e0b47f7b5: from storage DS-e513b6ec-517f-4438-bd91-31af0d185455 node DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 18:07:50,842 INFO BlockStateChange: BLOCK* processReport 0x56f0b69f8c2871fb: Processing first storage report for DS-6755ed7e-46ab-49db-a914-70207b487e68 from datanode d1ed285d-20a6-4d30-888b-6dc1293d773f
2021-06-16 18:07:50,842 INFO BlockStateChange: BLOCK* processReport 0x56f0b69f8c2871fb: from storage DS-6755ed7e-46ab-49db-a914-70207b487e68 node DatanodeRegistration(10.128.0.11:9866, datanodeUuid=d1ed285d-20a6-4d30-888b-6dc1293d773f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2021-06-16 18:07:51,721 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350) storage 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 18:07:51,721 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.128.0.9:9866
2021-06-16 18:07:51,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 108100fe-7661-4e2c-8041-5d1d21d2cc03 (10.128.0.9:9866).
2021-06-16 18:07:51,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 for DN 10.128.0.9:9866
2021-06-16 18:07:51,859 INFO BlockStateChange: BLOCK* processReport 0x64560d14e0476a69: Processing first storage report for DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 from datanode 108100fe-7661-4e2c-8041-5d1d21d2cc03
2021-06-16 18:07:51,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2021-06-16 18:07:51,866 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 2 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-16 18:07:51,868 INFO BlockStateChange: BLOCK* processReport 0x64560d14e0476a69: from storage DS-3d182c45-e5a2-43c3-a302-fd55fbe11ed3 node DatanodeRegistration(10.128.0.9:9866, datanodeUuid=108100fe-7661-4e2c-8041-5d1d21d2cc03, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 3, hasStaleStorage: false, processing time: 8 msecs, invalidatedBlocks: 0
2021-06-16 18:07:51,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 3
2021-06-16 18:07:51,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-16 18:07:51,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-16 18:07:51,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-16 18:07:51,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-16 18:07:51,885 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2021-06-16 18:08:11,895 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 3 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-16 18:08:21,897 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-16 18:08:21,897 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 33 secs
2021-06-16 18:08:21,897 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2021-06-16 18:08:21,897 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-16 18:08:54,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.128.0.9
2021-06-16 18:08:54,295 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-16 18:08:54,295 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 48, 48
2021-06-16 18:08:54,295 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 47 Number of syncs: 2 SyncTimes(ms): 10 
2021-06-16 18:08:54,297 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 47 Number of syncs: 3 SyncTimes(ms): 11 
2021-06-16 18:08:54,298 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000048 -> /home/hadoop/data/nameNode/current/edits_0000000000000000048-0000000000000000049
2021-06-16 18:08:54,298 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 50
2021-06-16 18:08:54,424 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/fsimage_0000000000000000046, fileSize: 1153. Sent total: 1153 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 18:08:54,447 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000047-0000000000000000047, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 18:08:54,465 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000048-0000000000000000049, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 18:08:54,769 INFO org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 1000.00 KB/s. Synchronous (fsync) write to disk of /home/hadoop/data/nameNode/current/fsimage.ckpt_0000000000000000049 took 0.00s.
2021-06-16 18:08:54,769 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000049 size 1153 bytes.
2021-06-16 18:08:54,773 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 46
2021-06-16 18:08:54,773 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2021-06-16 18:13:45,079 INFO org.apache.hadoop.http.HttpServer2: Process Thread Dump: jsp requested
47 active threads
Thread 59 (Scheduler-454884231):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 117
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 57 (CacheReplicationMonitor(1906680755)):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 12
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
    org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run(CacheReplicationMonitor.java:181)
Thread 56 (org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@49bf29c6):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 2
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber.run(FSNamesystem.java:4107)
    java.lang.Thread.run(Thread.java:748)
Thread 55 (org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3b718392):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 2
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller.run(FSNamesystem.java:4016)
    java.lang.Thread.run(Thread.java:748)
Thread 54 (org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor@c0b41d6):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 72
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor.run(FSNamesystem.java:3974)
    java.lang.Thread.run(Thread.java:748)
Thread 53 (org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@5d332969):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 180
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
    java.lang.Thread.run(Thread.java:748)
Thread 50 (pool-4-thread-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 49 (AsyncAppender-Dispatcher-Thread-32):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.ArrayList@2284d7dd
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
    java.lang.Thread.run(Thread.java:748)
Thread 48 (IPC Server handler 9 on 9000):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 400
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 47 (IPC Server handler 8 on 9000):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 409
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 46 (IPC Server handler 7 on 9000):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 417
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 45 (IPC Server handler 6 on 9000):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 365
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 44 (IPC Server handler 5 on 9000):
  State: TIMED_WAITING
  Blocked count: 7
  Waited count: 376
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 43 (IPC Server handler 4 on 9000):
  State: TIMED_WAITING
  Blocked count: 2
  Waited count: 361
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 42 (IPC Server handler 3 on 9000):
  State: TIMED_WAITING
  Blocked count: 7
  Waited count: 363
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 41 (IPC Server handler 2 on 9000):
  State: TIMED_WAITING
  Blocked count: 7
  Waited count: 385
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 40 (IPC Server handler 1 on 9000):
  State: TIMED_WAITING
  Blocked count: 2
  Waited count: 367
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 39 (IPC Server handler 0 on 9000):
  State: TIMED_WAITING
  Blocked count: 4
  Waited count: 358
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:287)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2664)
Thread 32 (IPC Server listener on 9000):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener.run(Server.java:1155)
Thread 35 (IPC Server Responder):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1330)
    org.apache.hadoop.ipc.Server$Responder.run(Server.java:1313)
Thread 28 (Block report processor):
  State: WAITING
  Blocked count: 0
  Waited count: 4
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@1b533f2c
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:4913)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:4902)
Thread 27 (StorageInfoMonitor):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StorageInfoDefragmenter.run(BlockManager.java:4589)
    java.lang.Thread.run(Thread.java:748)
Thread 26 (RedundancyMonitor):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 120
  Stack:
    java.lang.Thread.sleep(Native Method)
    java.lang.Thread.sleep(Thread.java:340)
    java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4554)
    java.lang.Thread.run(Thread.java:748)
Thread 29 (org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@c9d0d6):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 72
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run(HeartbeatManager.java:456)
    java.lang.Thread.run(Thread.java:748)
Thread 38 (DatanodeAdminMonitor-0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 12
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 37 (org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@27dc79f7):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 2
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
    java.lang.Thread.run(Thread.java:748)
Thread 34 (IPC Server idle connection scanner for port 9000):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 37
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 33 (Socket Reader #1 for port 9000):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1093)
    org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1072)
Thread 31 (FSEditLogAsync):
  State: WAITING
  Blocked count: 0
  Waited count: 4
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@da02d9b
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
    org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.dequeueEdit(FSEditLogAsync.java:221)
    org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.run(FSEditLogAsync.java:229)
    java.lang.Thread.run(Thread.java:748)
Thread 25 (org.eclipse.jetty.server.session.HashSessionManager@1ec9bd38Timer):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 12
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 24 (org.eclipse.jetty.server.session.HashSessionManager@22f59faTimer):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 12
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 23 (org.eclipse.jetty.server.session.HashSessionManager@769a1df5Timer):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 12
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 22 (qtp1523553211-22):
  State: RUNNABLE
  Blocked count: 2
  Waited count: 38
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 21 (qtp1523553211-21):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 42
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
    org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
    org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
    java.lang.Thread.run(Thread.java:748)
Thread 20 (qtp1523553211-20):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 44
  Stack:
    sun.management.ThreadImpl.getThreadInfo1(Native Method)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:185)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:144)
    org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:169)
    org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:253)
    org.apache.hadoop.http.HttpServer2$StackServlet.doGet(HttpServer2.java:1469)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
    org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
    org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
    org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
    org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
    org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
    org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
Thread 19 (qtp1523553211-19):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 44
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
    org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
    org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
    java.lang.Thread.run(Thread.java:748)
Thread 18 (qtp1523553211-18):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 41
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
    org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
    org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
    java.lang.Thread.run(Thread.java:748)
Thread 17 (qtp1523553211-17):
  State: TIMED_WAITING
  Blocked count: 7
  Waited count: 41
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
    org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
    org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
    java.lang.Thread.run(Thread.java:748)
Thread 16 (qtp1523553211-16-acceptor-0@27a4a2d7-ServerConnector@6dd7b5a3{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
    org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
    org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 15 (qtp1523553211-15):
  State: TIMED_WAITING
  Blocked count: 16
  Waited count: 37
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
    org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
    org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
    java.lang.Thread.run(Thread.java:748)
Thread 14 (pool-2-thread-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 13 (org.apache.hadoop.util.JvmPauseMonitor$Monitor@59af0466):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 718
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
    java.lang.Thread.run(Thread.java:748)
Thread 12 (Timer for 'NameNode' metrics system):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 36
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 4 (Signal Dispatcher):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
Thread 3 (Finalizer):
  State: WAITING
  Blocked count: 10
  Waited count: 10
  Waiting on java.lang.ref.ReferenceQueue$Lock@13b13b5d
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
Thread 2 (Reference Handler):
  State: WAITING
  Blocked count: 10
  Waited count: 10
  Waiting on java.lang.ref.Reference$Lock@2892dae4
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    java.lang.ref.Reference.tryHandlePending(Reference.java:191)
    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
Thread 1 (main):
  State: WAITING
  Blocked count: 3
  Waited count: 4
  Waiting on org.apache.hadoop.ipc.ProtobufRpcEngine$Server@71a49d6
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    org.apache.hadoop.ipc.Server.join(Server.java:3100)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.join(NameNodeRpcServer.java:576)
    org.apache.hadoop.hdfs.server.namenode.NameNode.join(NameNode.java:983)
    org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1712)

2021-06-16 18:48:53,509 INFO BlockStateChange: BLOCK* processReport 0x3545369e0b47f7b6: from storage DS-e513b6ec-517f-4438-bd91-31af0d185455 node DatanodeRegistration(10.128.0.10:9866, datanodeUuid=2e312f92-a5b9-43a0-9f20-c2777806fca7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-82850089-6c2f-498e-b4eb-816e5b0c5eae;nsid=1247811919;c=1623875689350), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2021-06-16 19:08:55,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.128.0.9
2021-06-16 19:08:55,090 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-16 19:08:55,090 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 50, 50
2021-06-16 19:08:55,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 12 
2021-06-16 19:08:55,092 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 13 
2021-06-16 19:08:55,094 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000050 -> /home/hadoop/data/nameNode/current/edits_0000000000000000050-0000000000000000051
2021-06-16 19:08:55,094 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 52
2021-06-16 19:08:55,115 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000050-0000000000000000051, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 19:08:55,140 INFO org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 1000.00 KB/s. Synchronous (fsync) write to disk of /home/hadoop/data/nameNode/current/fsimage.ckpt_0000000000000000051 took 0.00s.
2021-06-16 19:08:55,140 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000051 size 1153 bytes.
2021-06-16 19:08:55,142 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 49
2021-06-16 19:08:55,142 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000046, cpktTxId=0000000000000000046)
2021-06-16 20:08:55,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.128.0.9
2021-06-16 20:08:55,435 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-16 20:08:55,435 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 52, 52
2021-06-16 20:08:55,436 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2021-06-16 20:08:55,438 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2021-06-16 20:08:55,439 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hadoop/data/nameNode/current/edits_inprogress_0000000000000000052 -> /home/hadoop/data/nameNode/current/edits_0000000000000000052-0000000000000000053
2021-06-16 20:08:55,439 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 54
2021-06-16 20:08:55,460 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /home/hadoop/data/nameNode/current/edits_0000000000000000052-0000000000000000053, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2021-06-16 20:08:55,504 INFO org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 1000.00 KB/s. Synchronous (fsync) write to disk of /home/hadoop/data/nameNode/current/fsimage.ckpt_0000000000000000053 took 0.00s.
2021-06-16 20:08:55,504 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000053 size 1153 bytes.
2021-06-16 20:08:55,507 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 51
2021-06-16 20:08:55,508 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/hadoop/data/nameNode/current/fsimage_0000000000000000049, cpktTxId=0000000000000000049)
